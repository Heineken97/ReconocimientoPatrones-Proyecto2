{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autores Gabriel Conejo Valerio -2014093542 Nasser Brown Joseph Jimenez Zuñiga - 2016133677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout \n",
    "from keras.optimizers import Adam  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraccion de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"SetDeDatos/UTKFace\"  # Ruta al directorio de las imágenes\n",
    "image_files = os.listdir(data_path)\n",
    "images = []\n",
    "etiquetas = []\n",
    "for file in image_files:\n",
    "    if file.endswith('.jpg'):\n",
    "        # Carga la imagen en escala de grises\n",
    "        image = cv2.imread(os.path.join(data_path, file), cv2.IMREAD_GRAYSCALE)\n",
    "        # Extrae la edad del nombre del archivo (asumiendo que la edad es el primer número antes del guion bajo)\n",
    "        edad = int(file.split('_')[0])\n",
    "        images.append(image)\n",
    "        etiquetas.append(edad)\n",
    "# Convierte las listas en arreglos NumPy\n",
    "X = np.array(images)\n",
    "y = np.array(etiquetas)\n",
    "# Divide el conjunto de datos en entrenamiento y prueba\n",
    "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP (Perceptron Multicapa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronMulticapa:\n",
    "    def __init__(self, capas, F_activacion, alpha=0.1, epochs=1000):\n",
    "        self.capas = capas\n",
    "        self.alpha = alpha\n",
    "        self.epochs = epochs \n",
    "        self.F_activacion = F_activacion\n",
    "        self.bias = []\n",
    "        self.pesos = []\n",
    "        for i in range(0, len(capas) - 1):\n",
    "            peso = np.random.randn(capas[i], capas[i + 1])\n",
    "            self.pesos.append(peso)\n",
    "            bias = np.random.randn(capas[i + 1])\n",
    "            self.bias.append(bias)\n",
    "    def activacion(self, x,act):\n",
    "        if(act==\"sigmoid\"):\n",
    "            return 1.0 / (1 + np.exp(-x))\n",
    "        if(act==\"relu\"):\n",
    "            return(np.maximum(0, x))\n",
    "        if(act==\"tanh\"):\n",
    "             return np.tanh(x)\n",
    "    def activacion_derivada(self, x, act):\n",
    "      if act == \"sigmoid\":\n",
    "          return x * (1 - x)\n",
    "      if act == \"relu\":\n",
    "          return np.where(x <= 0, 0, 1)\n",
    "      if act == \"tanh\":\n",
    "          return 1 - np.tanh(x) ** 2\n",
    "      return x\n",
    "    def feedforward(self, X):\n",
    "        capa_activacion = [X]\n",
    "        for i in range(0, len(self.capas) - 1):\n",
    "            x = np.dot(capa_activacion[i], self.pesos[i]) + self.bias[i]\n",
    "            y = self.activacion(x,self.F_activacion[i])\n",
    "            capa_activacion.append(y)\n",
    "        return capa_activacion\n",
    "    def backpropagation(self, X, y, capa_activacion):\n",
    "        error = capa_activacion[-1] - y\n",
    "        deltas = [error]\n",
    "        for i in reversed(range(1, len(self.capas) - 1)):\n",
    "            delta = deltas[-1]\n",
    "            activacion = capa_activacion[i]\n",
    "            activacion_anterior = capa_activacion[i-1]\n",
    "            delta_anterior = np.dot(delta, self.pesos[i].T)\n",
    "            deltas.append(delta_anterior * self.activacion_derivada(activacion,self.F_activacion[-1]))\n",
    "        deltas = list(reversed(deltas))\n",
    "        for i in range(len(self.capas) - 1):\n",
    "            activacion_anterior = capa_activacion[i]\n",
    "            delta = deltas[i]\n",
    "            d_peso = np.outer(activacion_anterior, delta)\n",
    "            d_bias = delta\n",
    "            self.pesos[i] -= self.alpha * d_peso\n",
    "            self.bias[i] -= self.alpha * d_bias\n",
    "    def entrenar(self, X, y, epochs):\n",
    "        for epoch in range(0, epochs):\n",
    "            for i in range(0, len(X)):\n",
    "                # Feedforward\n",
    "                capa_activacion = self.feedforward(X[i])\n",
    "                # Backpropagation\n",
    "                self.backpropagation(X[i], y[i], capa_activacion)\n",
    "    def predecir(self, X):\n",
    "        # Obtener la salida de la última capa\n",
    "        capa_activacion = self.feedforward(X)\n",
    "        return capa_activacion[-1]\n",
    "def encode_labels(y):\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    y_encoded = encoder.fit_transform(y.reshape(-1, 1))\n",
    "    return y_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"SetDeDatos/UTKFace\"\n",
    "image_files = os.listdir(data_path)\n",
    "images = []\n",
    "etiquetas = []\n",
    "for file in image_files:\n",
    "    if file.endswith('.jpg'):\n",
    "        image = cv2.imread(os.path.join(data_path, file), cv2.IMREAD_GRAYSCALE)\n",
    "        edad = int(file.split('_')[0])\n",
    "        images.append(image)\n",
    "        etiquetas.append(edad)\n",
    "X = np.array(images)\n",
    "y = np.array(etiquetas)\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_entrenamiento_FE, X_prueba_FE, y_entrenamiento_FE, y_prueba_FE = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Aplanar las imágenes para que sean bidimensionales\n",
    "X_entrenamiento_FE = X_entrenamiento_FE.reshape(X_entrenamiento_FE.shape[0], -1)\n",
    "X_prueba_FE = X_prueba_FE.reshape(X_prueba_FE.shape[0], -1)\n",
    "# Definir el número de componentes principales deseado\n",
    "n_componentes = 50\n",
    "# Inicializar y ajustar el modelo PCA\n",
    "pca = PCA(n_components=n_componentes)\n",
    "X_entrenamiento_pca = pca.fit_transform(X_entrenamiento_FE)\n",
    "X_prueba_pca = pca.transform(X_prueba_FE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red sin Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_NoFE = PerceptronMulticapa(capas=[200, 150, 100, 103], F_activacion=[\"sigmoid\", \"relu\", \"tanh\",\"sigmoid\"], alpha=0.05, epochs=1000)\n",
    "y_entrenamiento_encoded_NoFE = encode_labels(y_entrenamiento)\n",
    "y_prueba_encoded_NoFE = encode_labels(y_prueba)\n",
    "perceptron_NoFE.entrenar(X_entrenamiento, y_entrenamiento_encoded_NoFE, epochs=3000)\n",
    "predicciones_encoded_NoFE = y_prueba_encoded_NoFE.predecir(X_prueba)\n",
    "# Decodificar las predicciones (seleccionar la clase con probabilidad mas alta)\n",
    "predicciones_NoFE = np.argmax(predicciones_encoded_NoFE, axis=1)\n",
    "accuracy_NoFE = accuracy_score(y_prueba, predicciones_NoFE)\n",
    "precision_NoFE = precision_score(y_prueba, predicciones_NoFE, average='weighted')\n",
    "recall_NoFE = recall_score(y_prueba, predicciones_NoFE, average='weighted')\n",
    "f1_NoFE = f1_score(y_prueba, predicciones_NoFE, average='weighted')\n",
    "print(\"Metricas red especifica sin Feature Eng [200, 150, 100, 103]\")\n",
    "print(f\"Accuracy: {accuracy_NoFE:.2f}\")\n",
    "print(f\"Precision (weighted): {precision_NoFE:.2f}\")\n",
    "print(f\"Recall (weighted): {recall_NoFE:.2f}\")\n",
    "print(f\"F1-score (weighted): {f1_NoFE:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red con Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_FE = PerceptronMulticapa(capas=[n_componentes, 150, 100, 103], F_activacion=[\"sigmoid\", \"relu\", \"tanh\", \"sigmoid\"], alpha=0.05, epochs=3000)\n",
    "perceptron_FE.entrenar(X_entrenamiento_pca, y_entrenamiento_FE, epochs=3000)\n",
    "predicciones_encoded_FE = perceptron_FE.predecir(X_prueba_pca)\n",
    "# Decodificar las predicciones (seleccionar la clase con probabilidad más alta)\n",
    "predicciones_FE = np.argmax(predicciones_encoded_FE, axis=1)\n",
    "accuracy_FE = accuracy_score(y_prueba_FE, predicciones_FE)\n",
    "precision_FE = precision_score(y_prueba_FE, predicciones_FE, average='weighted')\n",
    "recall_FE = recall_score(y_prueba_FE, predicciones_FE, average='weighted')\n",
    "f1_FE = f1_score(y_prueba_FE, predicciones_FE, average='weighted')\n",
    "print(\"Metricas red especifica con Feature Eng [200, 150, 100, 103]\")\n",
    "print(f\"Accuracy: {accuracy_FE:.2f}\")\n",
    "print(f\"Precision (weighted): {precision_FE:.2f}\")\n",
    "print(f\"Recall (weighted): {recall_FE:.2f}\")\n",
    "print(f\"F1-score (weighted): {f1_FE:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparacion entre Red sin Feature Extractor vs Red con Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparacion entre Red especifica [200, 150, 100, 103] con Feature Extractor y sin Feature Extractor\")\n",
    "print(f\"Accuracy con Feature Extractor: {accuracy_NoFE:.2f}\")\n",
    "print(f\"Precision con Feature Extractor: {precision_NoFE:.2f}\")\n",
    "print(f\"Recall con Feature Extractor: {recall_NoFE:.2f}\")\n",
    "print(f\"F1-score con Feature Extractor: {f1_NoFE:.2f}\")\n",
    "print(\"vs\")\n",
    "print(f\"Accuracy sin Feature Extractor: {accuracy_FE:.2f}\")\n",
    "print(f\"Precision sin Feature Extractor: {precision_FE:.2f}\")\n",
    "print(f\"Recall sin Feature Extractor: {recall_FE:.2f}\")\n",
    "print(f\"F1-score sin Feature Extractor: {f1_FE:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes Convolucionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrado de imagenes offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtro Bilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtro_bilateral(imagen, d, sigma_color, sigma_space):\n",
    "    imagen_filtrada = cv2.bilateralFilter(imagen, d, sigma_color, sigma_space)\n",
    "    return imagen_filtrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red Convolucional 1 en imagenes crudas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X = X.reshape(-1, 28, 28, 1)\n",
    "X_train_CCN1, X_test_CCN1, y_train_CCN1, y_test_CCN1 = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "y_train_CCN1 = to_categorical(y_train_CCN1.astype(np.int), num_classes=10)\n",
    "y_test_CCN1 = to_categorical(y_test_CCN1.astype(np.int), num_classes=10)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),padding=\"same\",strides=(1,1) ,activation='relu',input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1))) # este imput_shape no es necesario, ya que se hace solo\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train_CCN1, y_train_CCN1, batch_size=128, epochs=10, verbose=1)\n",
    "loss_CCN1, accuracy_CCN1 = model.evaluate(X_test_CCN1, y_test_CCN1, verbose=0)\n",
    "print(\"Red Convolucional 1 en imagenes crudas\")\n",
    "print(f\"Pérdida en el conjunto de prueba: {loss_CCN1}\")\n",
    "print(f\"Precisión en el conjunto de prueba: {accuracy_CCN1}\")\n",
    "print (\"La arquitectura del modelo es:  \")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red Convolucional 1 con \"Bilateral Filter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"SetDeDatos/UTKFace\" \n",
    "image_files = os.listdir(data_path)\n",
    "images = []\n",
    "etiquetas = []\n",
    "for file in image_files:\n",
    "    if file.endswith('.jpg'):\n",
    "        # Carga la imagen en escala de grises\n",
    "        image = cv2.imread(os.path.join(data_path, file), cv2.IMREAD_GRAYSCALE)\n",
    "        # Aplicar el filtro bilateral a la imagen\n",
    "        imagen_filtrada = filtro_bilateral(image, d=9, sigma_color=75, sigma_space=75)\n",
    "        # Extraer la edad del nombre del archivo (asumiendo que la edad es el primer numero antes del guion bajo)\n",
    "        edad = int(file.split('_')[0])\n",
    "        images.append(imagen_filtrada)  # Usar la imagen filtrada en lugar de la original\n",
    "        etiquetas.append(edad)\n",
    "X = np.array(images)\n",
    "y = np.array(etiquetas)\n",
    "X_entrenamiento_CCN1_FB, X_prueba_CCN1_FB, y_entrenamiento_CCN1_FB, y_prueba_CCN1_FB = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train_CCN1_FB = to_categorical(y_entrenamiento_CCN1_FB.astype(np.int), num_classes=10)\n",
    "y_test_CCN1_FB = to_categorical(y_prueba_CCN1_FB.astype(np.int), num_classes=10)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),padding=\"same\",strides=(1,1) ,activation='relu',input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1))) # este imput_shape no es necesario, ya que se hace solo\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(y_entrenamiento_CCN1_FB, y_train_CCN1_FB, batch_size=128, epochs=10, verbose=1)\n",
    "loss_CCN1_FB, accuracy_CCN1_FB = model.evaluate(y_prueba_CCN1_FB, y_test_CCN1_FB, verbose=0)\n",
    "print(\"Red Convolucional 2 con Filtro Bilateral\")\n",
    "print(f\"Pérdida en el conjunto de prueba: {loss_CCN1_FB}\")\n",
    "print(f\"Precisión en el conjunto de prueba: {accuracy_CCN1_FB}\")\n",
    "print (\"La arquitectura del modelo es:  \")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red Convolucional 2 en imagenes crudas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X = X.reshape(-1, 28, 28, 1)\n",
    "X_train_CCN2, X_test_CCN2, y_train_CCN2, y_test_CCN2 = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# Convertir las etiquetas a one-hot encoding\n",
    "y_train_CCN2 = to_categorical(y_train_CCN2.astype(np.int), num_classes=10)\n",
    "y_test_CCN2 = to_categorical(y_test_CCN2.astype(np.int), num_classes=10)\n",
    "model = Sequential()\n",
    "# Agregar capas convolucionales y de pooling\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Agregar una segunda capa convolucional y de pooling\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Agregar una capa de aplanamiento\n",
    "model.add(Flatten())\n",
    "# Agregar una capa completamente conectada con dropout para regularización\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout con una tasa del 50%\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "# Compilar el modelo con el optimizador Adam\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "model.fit(X_train_CCN2, y_train_CCN2, batch_size=128, epochs=10, verbose=1)\n",
    "loss_CCN2, accuracy_CCN2 = model.evaluate(X_test_CCN2, y_test_CCN2, verbose=0)\n",
    "print(\"Red Convolucional 2 en imagenes crudas\")\n",
    "print(f\"Pérdida en el conjunto de prueba: {loss_CCN2}\")\n",
    "print(f\"Precisión en el conjunto de prueba: {accuracy_CCN2}\")\n",
    "print(\"La arquitectura del modelo es:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red Convolucional 2 con \"Bilateral Filter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"SetDeDatos/UTKFace\"  # Ruta al directorio de las imágenes\n",
    "image_files = os.listdir(data_path)\n",
    "images = []\n",
    "etiquetas = []\n",
    "for file in image_files:\n",
    "    if file.endswith('.jpg'):\n",
    "        # Carga la imagen en escala de grises\n",
    "        image = cv2.imread(os.path.join(data_path, file), cv2.IMREAD_GRAYSCALE)\n",
    "        # Aplicar el filtro bilateral a la imagen\n",
    "        imagen_filtrada = filtro_bilateral(image, d=9, sigma_color=75, sigma_space=75)\n",
    "        # Extraer la edad del nombre del archivo (asumiendo que la edad es el primer número antes del guion bajo)\n",
    "        edad = int(file.split('_')[0])\n",
    "        images.append(imagen_filtrada)  # Usar la imagen filtrada en lugar de la original\n",
    "        etiquetas.append(edad)\n",
    "X = np.array(images)\n",
    "y = np.array(etiquetas)\n",
    "X_entrenamiento_CCN2_FB, X_prueba_CCN2_FB, y_entrenamiento_CCN2_FB, y_prueba_CCN2_FB = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train_CCN2_FB = to_categorical(y_train_CCN1_FB.astype(np.int), num_classes=10)\n",
    "y_test_CCN2_FB = to_categorical(y_test_CCN1_FB.astype(np.int), num_classes=10)\n",
    "model = Sequential()\n",
    "# Agregar capas convolucionales y de pooling\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Agregar una segunda capa convolucional y de pooling\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Agregar una capa de aplanamiento\n",
    "model.add(Flatten())\n",
    "# Agregar una capa completamente conectada con dropout para regularización\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout con una tasa del 50%\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "# Compilar el modelo con el optimizador Adam\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "model.fit(X_entrenamiento_CCN2_FB, y_train_CCN2_FB, batch_size=128, epochs=10, verbose=1)\n",
    "loss_CCN2_FB, accuracy_CCN2_FB = model.evaluate(X_prueba_CCN2_FB, y_test_CCN2_FB, verbose=0)\n",
    "print(\"Red Convolucional 2 con Filtro Bilateral\")\n",
    "print(f\"Pérdida en el conjunto de prueba: {loss_CCN2_FB}\")\n",
    "print(f\"Precisión en el conjunto de prueba: {accuracy_CCN2_FB}\")\n",
    "print(\"La arquitectura del modelo es:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla de Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respuesta a las preguntas\n",
    "¿Cual es el tamano de los modelos?\n",
    "¿Cual es la arquitectura (cuales y cuantas capas se utilizaron)?\n",
    "¿Que ventajas tiene utilizar un feature extractor? referirse a las metricas y tiempos\n",
    "¿Que modelo se entrena mas rapido?\n",
    "¿Cuales secciones de la imagen son las mas importantes para la eleccion?\n",
    "¿Cual fue el mejor modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
